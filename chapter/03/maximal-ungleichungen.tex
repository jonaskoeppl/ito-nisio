\section{Maximalungleichungen}

\begin{mydef}
    Eine E-wertige Zufallsvariable $X$ heißt \textit{symmetrisch}, falls $-X$ die selbe Verteilung besitzt wie $X$, d.h.
    \begin{align*}
        \forall A \in \mathcal{B}(E): P(\{X \in A\}) = P(\{-X \in A\}). 
    \end{align*}
\end{mydef}

\begin{remark}
    Nach dem Eindeutigkeitssatz für charakteristische Funktionale ist eine Zufallsvariable $X \in \mathcal{L}_0(E)$ genau dann symmetrisch, wenn 
    $$
        \forall z \in E': \quad \widehat{\mu_X}(z) = \widehat{\mu_{-X}}(z). 
    $$
\end{remark}

\begin{mydef}%TODO: Wird das überhaupt gebraucht? Ggf schöner formulieren. 
    Eine Folge $(X_n)_{n \in \N}$ von E-wertigen Zufallsvariablen heißt \textit{symmetrisch}, 
    falls $(\varepsilon_1 X_1, \varepsilon_2 X_2,...)$ für jede Wahl von $\varepsilon_i = \pm 1$ 
    die gleiche Verteilung hat wie $(X_1,X_2,...)$. 
\end{mydef}

\begin{remark}
   Sind $X_1,X_2,...$ unabhängige E-wertige Zufallsvariablen, sodass $X_n$ für alle $n \in \N$ symmetrisch ist, dann ist $(X_1,X_2,...)$ symmetrisch. 
\end{remark}

\begin{theorem}[Lévys Maximal-Ungleichung]
    Seien $X_1,...,X_N \in L_0(E)$ unabhängige und symmetrische Zufallsvariablen und setze 
    \begin{align*}
        S_n := \sum_{i=1}^n X_i, \quad 1 \leq n \leq N. 
    \end{align*}
    Dann gilt für alle $t > 0$
    \begin{align}
        &P\big(\{ \max_{1 \leq n \leq N} \norm{S_n} > t \}\big) \leq 2 P\big(\{\norm{S_N} > t \}\big), \\\
        &P\big(\{ \max_{1 \leq n \leq N} \norm{X_n} > t \}\big) \leq 2 P\big(\{\norm{S_N} > t \}\big).
    \end{align}
\end{theorem}

\begin{proof*}
    zu $(3.1)$:
    Setze 
    $$
        T_1(\omega) := \inf\{ k \leq N: \norm{S_k} > t \} \in [0, \infty], \quad \omega \in \Omega. 
    $$
    Dann ist $T_1$ messbar, da für jedes $i =1,...,N$ die Menge $\{ \norm{S_i} \leq t\}$ messbar ist. 
    Wir zeigen zunächst
    \begin{align}
        \{T_1 = n\} \subseteq \{\norm{S_N} > t, T_1 = n\} \cup \{\norm{2S_n - S_N}>t, T_1=n\}, \quad n \in \{1,...,N\}, \\\
        \prob{\norm{S_N} > t, T_1=n} = \prob{\norm{2S_n - S_N} > t, T_1=n}, \quad n \in \{1,...,N\}. 
    \end{align}
    zu $(3.3)$:
    Für $\omega \in \Omega$ mit $T_1(\omega) = n$ und $\norm{S_N} \leq t$ liefert die umgekehrte Dreiecksungleichung
    $$
        \norm{2S_n - S_N} \geq 2\norm{S_n} - \norm{S_N} > 2t - t = t. 
    $$
    zu $(3.4)$: Setze $\varepsilon_1 = \varepsilon_2 = ... = \varepsilon_n = 1$ und $\varepsilon_{n+1} = ... = \varepsilon_N = -1$, sowie
    $$
        S'_j := \sum_{i=1}^N\varepsilon_i X_i. 
    $$
    Dann gilt $S_j = S'_j$ für alle $j \leq n$ und 
    $$
        2S_n - S_N = 2 \sum_{i=1}^n X_i - \sum_{i=1}^N X_I = \sum_{i=1}^nX_i - \sum_{i=n+1}^N X_i = S'_N. 
    $$
    Wegen der Symmetrie von $X_1,...,X_N$ sind $(S_1,...,S_N)$ und $(S'_1,...,S'_N)$ identisch verteilt. Also ergibt sich 
    \begin{align*}
        \prob{\norm{S_N} > t, T_1=n} &= \prob{\norm{S_1} \leq t,...,\norm{S_{n-1}}\leq t, \norm{S_n} > t, \norm{S_N} > t} \\\
                                   &= \prob{\norm{S'_1}\leq t,...,\norm{S'_{n-1}}\leq t, \norm{S'_n} > t, \norm{S'_N} > t} \\\
                                   &= \prob{\norm{2S_n - S_N} > t, T_1=n}. 
    \end{align*}
    Wir erhalten also mit $(3.3)$ und $(3.4)$ 
    $$
        \prob{T_1=n} \leq 2 \prob{\norm{S_N} > t, T_1=n}.
    $$
    Woraus wir schließlich $(3.1)$ folgern  
    \begin{align*}
        \prob{\max_{1 \leq n \leq N} \norm{S_n} > t} \leq \sum_{n=1}^{N} \prob{T_1=n} 
                                                     &\leq \sum_{n=1}^N2\prob{\norm{S_N} >t, T=n} \\\
                                                     &= 2 \prob{\norm{S_N}>t, T_1 \leq N} \leq 2 \prob{\norm{S_N} > t}. 
    \end{align*}
    zu $(3.2)$: 
    Setze 
    $$
        T_2(\omega) := \inf\{k \leq N: \norm{X_k(\omega)} > t\} \in [0, \infty], \quad \omega \in \Omega. 
    $$
    Analog zum Beweis von $(3.3)$ und $(3.4)$ zeigt man 
    \begin{align*}
        \{T_2 = n\} \subseteq \{\norm{S_N} > t, T_2 =n\} \cup \{\norm{2X_n - S_N} > t, T_2=n\}, \quad n \in \{1,...,N\}, \\\
        \prob{\norm{S_N} > t, T_2 = n} = \prob{\norm{2X_n - S_N}, T_2 = n}, \quad n \in \{1,...,N\}. 
    \end{align*}
    unter der Verwendung der Symmetrie von $X_1,...,X_N$ und folgert daraus schließlich 
    \begin{align*}
        \prob{\max_{1\leq n \leq N} \norm{X_n} > t} = \sum_{n=1}^N \prob{T_2 = n} 
                                                    &\leq \sum_{n=1}^N 2\prob{\norm{S_N} > t, T=n} \\\
                                                    &= 2 \prob{\norm{S_N}>t, T_2 \leq N} \leq 2 \prob{\norm{S_N} > t}. 
    \end{align*}
    \qed 
\end{proof*}

Für nicht-symmetrische Zufallsvariablen erhalten wir mit einer ähnlichen Beweismethode die folgende auf Giuseppe Ottaviani und Anatoli Skorohod zurückgehende Maximal-Ungleichung, vgl. \cite{ledoux-talagrand}[Lemma 6.2]. 
\begin{theorem}[Maximal-Ungleichung von Ottaviani-Skorohod]
    Seien $X_1,...,X_N$ unabhängige $E$-wertige Zufallsvariablen, $N \in \N$. Setze 
    $$
        S_k := \sum_{i=1}^kX_i, \quad k = 1,...,N. 
    $$
    Dann gilt für alle $s,t > 0$
    \begin{align}
        P(\{ \max_{1 \leq k \leq N} \norm{S_k} > s + t \}) \leq \frac{P(\{\norm{S_N} > t \})}{1 - \max_{1 \leq k \leq N}P(\{ \norm{S_N - S_k} > s \})} \ . 
    \end{align}
\end{theorem}

\begin{proof*}
    Setze 
    $$
        T(\omega) := \inf\{k \leq N: \norm{S_k(\omega)} > s + t\} \in [0, \infty], \quad \omega \in \Omega. 
    $$
    Dann ist $T$ messbar und $\{T = k\}$ hängt nur von $X_1,...,X_k$ ab. Weiter gilt 
    $$
        \sum_{k=1}^N \prob{T = k} = \prob{\max_{1\leq k \leq N}\norm{S_k} > s+t}.
    $$
    Für $\omega \in \Omega$ mit $T(\omega) = k$ und $\norm{S_N - S_k} \leq s$ gilt zudem $\norm{S_N} > t$, denn mit der umgekehrten Dreiecksungleichung erhält man
    $$
        s \geq \norm{S_N - S_k} \geq \abs{\norm{S_N}-\norm{S_k}} > (s+t) - \norm{S_N}.
    $$
    Die Unabhängigkeit von $X_1,...,X_N$ liefert schließlich
    \begin{align*}
        \prob{\norm{S_N} > t} &\geq \sum_{k=1}^N \prob{T=k, \norm{S_N} > t}  \\\
                              &\geq \sum_{k=1}^N \prob{T=k, \norm{S_N - S_k} \leq s} \\\
                              &\geq \min_{1\leq k \leq N}\prob{\norm{S_N-S_k} \leq s} \sum_{k=1}^N \prob{T=k}. 
    \end{align*}
    Umstellen und beachten von 
    $$
        \min_{1\leq k \leq N}\prob{\norm{S_N-S_k} \leq s} = 1 - \max_{1\leq k \leq N}\prob{\norm{S_N - s_k} > s}
    $$
    liefert nun die Behauptung. \qed
\end{proof*}